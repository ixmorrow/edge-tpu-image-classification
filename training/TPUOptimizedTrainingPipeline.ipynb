{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile tpu_training.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, Model\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class TPUTrainingPipeline:\n",
        "    def __init__(self, num_classes=5):\n",
        "        self.num_classes = num_classes\n",
        "        self.history = {}\n",
        "\n",
        "        # Initialize TPU strategy\n",
        "        try:\n",
        "            resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "            tf.config.experimental_connect_to_cluster(resolver)\n",
        "            tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "            self.strategy = tf.distribute.TPUStrategy(resolver)\n",
        "            print(f\"Training on TPU: {resolver.cluster_spec().as_dict()}\")\n",
        "        except ValueError:\n",
        "            print(\"No TPU detected. Using CPU/GPU strategy\")\n",
        "            self.strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "        print(f'Number of replicas: {self.strategy.num_replicas_in_sync}')\n",
        "\n",
        "        # TPU-optimized batch size\n",
        "        self.batch_size = 128 * self.strategy.num_replicas_in_sync\n",
        "        self.image_size = (224, 224)\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"Create model within TPU strategy scope\"\"\"\n",
        "        with self.strategy.scope():\n",
        "            base_model = MobileNetV2(\n",
        "                weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=(*self.image_size, 3)\n",
        "            )\n",
        "\n",
        "            base_model.trainable = False\n",
        "\n",
        "            x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "            # TPU-optimized attention mechanism\n",
        "            attention = layers.Dense(512, activation='relu')(x)\n",
        "            attention = layers.Dense(x.shape[-1], activation='sigmoid')(attention)\n",
        "            attention_output = layers.Multiply()([x, attention])\n",
        "\n",
        "            # TPU-friendly layer sizes (powers of two)\n",
        "            x = layers.Dense(512, activation='relu')(attention_output)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Dense(256, activation='relu')(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "            model = Model(base_model.input, outputs)\n",
        "\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "            return model\n",
        "\n",
        "    def create_dataset(self, dataset, is_training=True):\n",
        "        \"\"\"Create TPU-optimized dataset pipeline\"\"\"\n",
        "        AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "        @tf.function\n",
        "        def preprocess(image, label):\n",
        "            image = tf.cast(image, tf.float32)\n",
        "            image = tf.image.resize(image, self.image_size)\n",
        "            image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "            return image, label\n",
        "\n",
        "        @tf.function\n",
        "        def augment(image, label):\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "            image = tf.image.random_brightness(image, 0.2)\n",
        "            return image, label\n",
        "\n",
        "        dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "        if is_training:\n",
        "            dataset = dataset.map(augment, num_parallel_calls=AUTOTUNE)\n",
        "            dataset = dataset.shuffle(10000)\n",
        "\n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n",
        "        dataset = dataset.prefetch(AUTOTUNE)\n",
        "        return dataset\n",
        "\n",
        "    def train(self, train_dataset, val_dataset, epochs=10):\n",
        "        \"\"\"Train the model using TPU-optimized settings\"\"\"\n",
        "        callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=3,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                'best_model.h5',\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                mode='max'\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.2,\n",
        "                patience=2,\n",
        "                min_lr=0.0001\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        model = self.create_model()\n",
        "        history = model.fit(\n",
        "            train_dataset,\n",
        "            validation_data=val_dataset,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "\n",
        "        # Return results in same format as base pipeline for fair comparison\n",
        "        return {\n",
        "            'accuracy': [float(x) for x in history.history['accuracy']],\n",
        "            'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
        "            'loss': [float(x) for x in history.history['loss']],\n",
        "            'val_loss': [float(x) for x in history.history['val_loss']]\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04o4L9PMBJ2Y",
        "outputId": "1e2001e1-b4a6-45ce-f303-09de8d3891dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tpu_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile baseline_training.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, Model\n",
        "import multiprocessing\n",
        "import os\n",
        "\n",
        "class BaseTrainingPipeline:\n",
        "    def __init__(self, num_classes=5):\n",
        "        self.num_classes = num_classes\n",
        "        self.history = {}\n",
        "        self.model = None\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.quantized_model = None\n",
        "        # Add batch size as class attribute for benchmarking\n",
        "        self.batch_size = 32\n",
        "        self.image_size = (224, 224)\n",
        "\n",
        "    def create_model(self):  # Remove num_classes parameter as it's a class attribute\n",
        "        \"\"\"Create a fine-tunable MobileNetV2 model\"\"\"\n",
        "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(*self.image_size, 3))\n",
        "\n",
        "        # Freeze the base model\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Add custom classification head\n",
        "        x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "        x = layers.Dense(128, activation='relu')(x)\n",
        "        x = layers.Dropout(0.2)(x)\n",
        "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "        model = Model(base_model.input, outputs)\n",
        "\n",
        "        # Compile model here to match benchmark requirements\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model  # Return model instead of setting self.model\n",
        "\n",
        "    def preprocess_data(self, image, label):\n",
        "        \"\"\"Preprocess images for MobileNetV2\"\"\"\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image = tf.image.resize(image, self.image_size)\n",
        "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "        return image, label\n",
        "\n",
        "    def create_dataset(self, dataset, is_training=True):  # Add is_training parameter to match TPU pipeline\n",
        "        \"\"\"Create an optimized tf.data pipeline\"\"\"\n",
        "        AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "        dataset = dataset.map(self.preprocess_data, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "        if is_training:\n",
        "            dataset = dataset.cache().shuffle(1000)\n",
        "\n",
        "        return dataset.batch(self.batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "    def train(self, train_dataset, val_dataset, epochs=5):  # Modified to match benchmark interface\n",
        "        \"\"\"Train the model using an efficient training loop\"\"\"\n",
        "        model = self.create_model()\n",
        "\n",
        "        # Use multiple workers for training\n",
        "        train_workers = min(multiprocessing.cpu_count(), 4)\n",
        "\n",
        "        history = model.fit(\n",
        "            train_dataset,\n",
        "            validation_data=val_dataset,\n",
        "            epochs=epochs,\n",
        "            workers=train_workers,\n",
        "            use_multiprocessing=True\n",
        "        )\n",
        "\n",
        "        # Return results in the same format as TPU pipeline\n",
        "        return {\n",
        "            'accuracy': [float(x) for x in history.history['accuracy']],\n",
        "            'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
        "            'loss': [float(x) for x in history.history['loss']],\n",
        "            'val_loss': [float(x) for x in history.history['val_loss']]\n",
        "        }\n",
        "\n",
        "    def quantize_model(self, model, train_dataset):  # Add train_dataset parameter\n",
        "        \"\"\"Convert model to TFLite format with quantization\"\"\"\n",
        "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "        # Enable quantization\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "        converter.inference_input_type = tf.uint8\n",
        "        converter.inference_output_type = tf.uint8\n",
        "\n",
        "        # Representative dataset for quantization\n",
        "        def representative_dataset():\n",
        "            for data in train_dataset.take(100):\n",
        "                yield [tf.dtypes.cast(data[0], tf.float32)]\n",
        "\n",
        "        converter.representative_dataset = representative_dataset\n",
        "\n",
        "        # Convert the model\n",
        "        quantized_tflite_model = converter.convert()\n",
        "\n",
        "        # Save the quantized model\n",
        "        with open('quantized_model.tflite', 'wb') as f:\n",
        "            f.write(quantized_tflite_model)\n",
        "\n",
        "        return quantized_tflite_model  # Return instead of setting self.quantized_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MELTbvIlBU56",
        "outputId": "ad095554-f3c2-4bc6-c4c0-a1914a7c4c60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing baseline_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "class PerformanceBenchmark:\n",
        "    def __init__(self, base_pipeline, tpu_pipeline):\n",
        "        self.base_pipeline = base_pipeline\n",
        "        self.tpu_pipeline = tpu_pipeline\n",
        "        self.results = {}\n",
        "\n",
        "    def benchmark_training_step(self, model, dataset, num_steps=100):\n",
        "        \"\"\"Measure average training step time\"\"\"\n",
        "        step_times = []\n",
        "\n",
        "        for batch in dataset.take(num_steps):\n",
        "            start_time = time.perf_counter()\n",
        "            _ = model.train_on_batch(*batch)\n",
        "            step_times.append(time.perf_counter() - start_time)\n",
        "\n",
        "        return {\n",
        "            'avg_step_time': np.mean(step_times),\n",
        "            'std_step_time': np.std(step_times),\n",
        "            'min_step_time': np.min(step_times),\n",
        "            'max_step_time': np.max(step_times)\n",
        "        }\n",
        "\n",
        "    def measure_throughput(self, model, dataset, pipeline, num_steps=100):\n",
        "        \"\"\"Calculate images processed per second\"\"\"\n",
        "        batch_size = pipeline.batch_size\n",
        "        total_images = batch_size * num_steps\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        for batch in dataset.take(num_steps):\n",
        "            _ = model.predict_on_batch(batch[0])\n",
        "        total_time = time.perf_counter() - start_time\n",
        "\n",
        "        return {\n",
        "            'images_per_second': total_images / total_time,\n",
        "            'batch_size': batch_size,\n",
        "            'total_time': total_time\n",
        "        }\n",
        "\n",
        "    def _benchmark_pipeline(self, pipeline, train_ds, val_ds, epochs, name):\n",
        "        \"\"\"Run benchmark for a single pipeline\"\"\"\n",
        "        # Prepare datasets\n",
        "        train_dataset = pipeline.create_dataset(train_ds, is_training=True)\n",
        "        val_dataset = pipeline.create_dataset(val_ds, is_training=False)\n",
        "\n",
        "        # Create model\n",
        "        model = pipeline.create_model()\n",
        "\n",
        "        # Measure throughput\n",
        "        throughput_metrics = self.measure_throughput(model, val_dataset, pipeline)\n",
        "\n",
        "        # Measure Step metrics\n",
        "        step_metrics = self.benchmark_training_step(model, train_dataset)\n",
        "\n",
        "        # Train model and measure time\n",
        "        start_time = time.perf_counter()\n",
        "        history = pipeline.train(train_dataset, val_dataset, epochs)\n",
        "        training_time = time.perf_counter() - start_time\n",
        "\n",
        "        return {\n",
        "            'name': name,\n",
        "            'throughput_metrics': throughput_metrics,\n",
        "            'training_metrics': {\n",
        "                'total_time': training_time,\n",
        "                'epochs': epochs,\n",
        "                'history': history\n",
        "            },\n",
        "            'model_metrics': {\n",
        "                'total_params': model.count_params(),\n",
        "                'batch_size': pipeline.batch_size\n",
        "            },\n",
        "            'step_metrics': step_metrics\n",
        "        }\n",
        "\n",
        "    def run_full_benchmark(self, train_dataset, val_dataset, epochs=2):\n",
        "        \"\"\"Run comprehensive benchmark comparing both pipelines\"\"\"\n",
        "        results = {\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'hardware_info': self._get_hardware_info(),\n",
        "            'pipelines': {}\n",
        "        }\n",
        "\n",
        "        # Benchmark base pipeline\n",
        "        print(\"Benchmarking base pipeline...\")\n",
        "        base_metrics = self._benchmark_pipeline(\n",
        "            self.base_pipeline, train_dataset, val_dataset,\n",
        "            epochs, \"Base Pipeline\"\n",
        "        )\n",
        "        results['pipelines']['base'] = base_metrics\n",
        "\n",
        "        # Benchmark TPU pipeline\n",
        "        print(\"\\nBenchmarking TPU-optimized pipeline...\")\n",
        "        tpu_metrics = self._benchmark_pipeline(\n",
        "            self.tpu_pipeline, train_dataset, val_dataset,\n",
        "            epochs, \"TPU Pipeline\"\n",
        "        )\n",
        "        results['pipelines']['tpu'] = tpu_metrics\n",
        "\n",
        "        # Save results\n",
        "        self._save_results(results)\n",
        "\n",
        "        # Generate visualizations\n",
        "        self._generate_visualizations(results)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _get_hardware_info(self):\n",
        "        \"\"\"Gather information about available hardware\"\"\"\n",
        "        gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "        tpu_devices = tf.config.list_physical_devices('TPU')\n",
        "\n",
        "        return {\n",
        "            'num_gpus': len(gpu_devices),\n",
        "            'num_tpus': len(tpu_devices),\n",
        "            'tpu_type': self._get_tpu_type() if tpu_devices else None,\n",
        "            'tensorflow_version': tf.__version__\n",
        "        }\n",
        "\n",
        "    def _get_tpu_type(self):\n",
        "        \"\"\"Get TPU type if available\"\"\"\n",
        "        try:\n",
        "            resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "            return str(resolver.cluster_spec())\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _save_results(self, results):\n",
        "        \"\"\"Save benchmark results to file\"\"\"\n",
        "        Path('benchmark_results').mkdir(exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        with open(f'benchmark_results/benchmark_{timestamp}.json', 'w') as f:\n",
        "            json.dump(results, f, indent=4)\n",
        "\n",
        "    def _generate_visualizations(self, results):\n",
        "        \"\"\"Generate performance comparison visualizations\"\"\"\n",
        "        Path('benchmark_plots').mkdir(exist_ok=True)\n",
        "\n",
        "        # Training time comparison\n",
        "        self._plot_training_comparison(results)\n",
        "\n",
        "        # Throughput comparison\n",
        "        self._plot_throughput_comparison(results)\n",
        "\n",
        "        # Training metrics over time\n",
        "        self._plot_training_metrics(results)\n",
        "\n",
        "    def _plot_training_comparison(self, results):\n",
        "        \"\"\"Plot training time comparisons\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        pipelines = list(results['pipelines'].keys())\n",
        "        times = [results['pipelines'][p]['training_metrics']['total_time']\n",
        "                for p in pipelines]\n",
        "\n",
        "        plt.bar(pipelines, times)\n",
        "        plt.title('Total Training Time Comparison')\n",
        "        plt.ylabel('Time (seconds)')\n",
        "        plt.savefig('benchmark_plots/training_time_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_throughput_comparison(self, results):\n",
        "        \"\"\"Plot throughput comparisons\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        pipelines = list(results['pipelines'].keys())\n",
        "        throughputs = [results['pipelines'][p]['throughput_metrics']['images_per_second']\n",
        "                      for p in pipelines]\n",
        "\n",
        "        plt.bar(pipelines, throughputs)\n",
        "        plt.title('Image Processing Throughput Comparison')\n",
        "        plt.ylabel('Images per Second')\n",
        "        plt.savefig('benchmark_plots/throughput_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_training_metrics(self, results):\n",
        "        \"\"\"Plot training metrics over time\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        for pipeline_name, pipeline_data in results['pipelines'].items():\n",
        "            history = pipeline_data['training_metrics']['history']\n",
        "\n",
        "            plt.plot(history['val_accuracy'],\n",
        "                    label=f'{pipeline_name} Validation Accuracy')\n",
        "\n",
        "        plt.title('Training Progress Comparison')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Validation Accuracy')\n",
        "        plt.legend()\n",
        "        plt.savefig('benchmark_plots/training_progress.png')\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "0gsLMC2mN3tg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from baseline_training import BaseTrainingPipeline\n",
        "from tpu_training import TPUTrainingPipeline\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load dataset\n",
        "(train_ds, val_ds), dataset_info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[20%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# Initialize pipelines\n",
        "base_pipeline = BaseTrainingPipeline(num_classes=5)\n",
        "tpu_pipeline = TPUTrainingPipeline(num_classes=5)\n",
        "\n",
        "# Initialize and run benchmark\n",
        "benchmark = PerformanceBenchmark(base_pipeline, tpu_pipeline)\n",
        "results = benchmark.run_full_benchmark(train_ds, val_ds, epochs=2)\n",
        "\n",
        "# Print summary\n",
        "print(\"\\nBenchmark Summary:\")\n",
        "print(\"-\" * 50)\n",
        "for pipeline_name, pipeline_data in results['pipelines'].items():\n",
        "    print(f\"\\n{pipeline_name} Pipeline:\")\n",
        "    print(f\"Total training time: {pipeline_data['training_metrics']['total_time']:.2f} seconds\")\n",
        "    print(f\"Images per second: {pipeline_data['throughput_metrics']['images_per_second']:.2f}\")\n",
        "    print(f\"Total Model Parameters: {pipeline_data['model_metrics']['total_params']}\")\n",
        "    print(f\"Batch Size: {pipeline_data['model_metrics']['batch_size']}\")\n",
        "    print(f\"Average step time: {pipeline_data['step_metrics']['avg_step_time'] * 1000:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBQ3unCpM5ch",
        "outputId": "3773a521-f9f7-415c-f373-3dec4fa209cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on TPU: {}\n",
            "Number of replicas: 8\n",
            "Benchmarking base pipeline...\n",
            "Epoch 1/2\n",
            "92/92 [==============================] - 40s 401ms/step - loss: 0.5940 - accuracy: 0.7820 - val_loss: 0.2630 - val_accuracy: 0.9108\n",
            "Epoch 2/2\n",
            "92/92 [==============================] - 35s 384ms/step - loss: 0.2772 - accuracy: 0.9022 - val_loss: 0.1776 - val_accuracy: 0.9479\n",
            "\n",
            "Benchmarking TPU-optimized pipeline...\n",
            "Epoch 1/2\n",
            "1/2 [==============>...............] - ETA: 11s - loss: 2.3968 - accuracy: 0.1973"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 22s 11s/step - loss: 1.5775 - accuracy: 0.4844 - val_loss: 0.8158 - val_accuracy: 0.7905 - lr: 0.0020\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 5s 4s/step - loss: 0.3486 - accuracy: 0.8784 - val_loss: 0.6438 - val_accuracy: 0.8105 - lr: 0.0020\n",
            "\n",
            "Benchmark Summary:\n",
            "--------------------------------------------------\n",
            "\n",
            "base Pipeline:\n",
            "Total training time: 76.22 seconds\n",
            "Images per second: 142.42\n",
            "Total Model Parameters: 2422597\n",
            "Batch Size: 32\n",
            "Average step time: 264.41 ms\n",
            "\n",
            "tpu Pipeline:\n",
            "Total training time: 39.69 seconds\n",
            "Images per second: 11337.29\n",
            "Total Model Parameters: 4362053\n",
            "Batch Size: 1024\n",
            "Average step time: 7081.33 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "def load_and_analyze_results(file_path):\n",
        "    \"\"\"Load and analyze benchmark results\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    # Create analysis sections\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Edge TPU Performance Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. Basic Performance Metrics\n",
        "    print(\"\\n1. Basic Performance Metrics:\")\n",
        "    print(\"-\" * 30)\n",
        "    metrics_comparison = pd.DataFrame({\n",
        "        'Metric': ['First Inference Time (ms)', 'Average Inference Time (ms)', 'Inference Time Std (ms)', 'Throughput (FPS)'],\n",
        "        'With Warmup': [\n",
        "            results['warmup']['detailed_performance_metrics']['inference_times'][0],\n",
        "            results['warmup']['summary']['average_inference_time_ms'],\n",
        "            results['warmup']['summary']['inference_time_std_ms'],\n",
        "            results['warmup']['summary']['throughput_fps']\n",
        "        ],\n",
        "        'Without Warmup': [\n",
        "            results['warmup']['detailed_performance_metrics']['inference_times'][0],\n",
        "            results['no_warmup']['summary']['average_inference_time_ms'],\n",
        "            results['no_warmup']['summary']['inference_time_std_ms'],\n",
        "            results['no_warmup']['summary']['throughput_fps']\n",
        "        ]\n",
        "    })\n",
        "    print(metrics_comparison.to_string(index=False))\n",
        "\n",
        "    # 2. Detailed Timing Analysis\n",
        "    print(\"\\n2. Detailed Timing Analysis:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    def analyze_timing_component(name, warm_times, no_warm_times):\n",
        "        warm_stats = {\n",
        "            'mean': np.mean(warm_times),\n",
        "            'std': np.std(warm_times),\n",
        "            'p95': np.percentile(warm_times, 95),\n",
        "            'p99': np.percentile(warm_times, 99)\n",
        "        }\n",
        "        no_warm_stats = {\n",
        "            'mean': np.mean(no_warm_times),\n",
        "            'std': np.std(no_warm_times),\n",
        "            'p95': np.percentile(no_warm_times, 95),\n",
        "            'p99': np.percentile(no_warm_times, 99)\n",
        "        }\n",
        "        return pd.DataFrame({\n",
        "            'Metric': [f'{name} Mean (ms)', f'{name} Std (ms)', f'{name} P95 (ms)', f'{name} P99 (ms)'],\n",
        "            'With Warmup': [warm_stats['mean'], warm_stats['std'], warm_stats['p95'], warm_stats['p99']],\n",
        "            'Without Warmup': [no_warm_stats['mean'], no_warm_stats['std'], no_warm_stats['p95'], no_warm_stats['p99']]\n",
        "        })\n",
        "\n",
        "    timing_components = ['preprocessing_times', 'inference_times', 'invoke_times', 'overhead_times']\n",
        "    all_timing_stats = pd.DataFrame()\n",
        "\n",
        "    for component in timing_components:\n",
        "      if component in results['warmup']['detailed_performance_metrics'] and component in results['no_warmup']['detailed_performance_metrics']:\n",
        "        warm_times = results['warmup']['detailed_performance_metrics'][component]\n",
        "        no_warm_times = results['no_warmup']['detailed_performance_metrics'][component]\n",
        "        component_stats = analyze_timing_component(component.replace('_times', ''), warm_times, no_warm_times)\n",
        "        all_timing_stats = pd.concat([all_timing_stats, component_stats])\n",
        "\n",
        "    print(all_timing_stats.to_string(index=False))\n",
        "\n",
        "    # 3. Performance Stability Analysis\n",
        "    print(\"\\n3. Performance Stability Analysis:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    def analyze_stability(times):\n",
        "        return {\n",
        "            'coefficient_of_variation': np.std(times) / np.mean(times),\n",
        "            'range': np.max(times) - np.min(times),\n",
        "            'iqr': np.percentile(times, 75) - np.percentile(times, 25)\n",
        "        }\n",
        "\n",
        "    warm_stability = analyze_stability(results['warmup']['detailed_performance_metrics']['inference_times'])\n",
        "    no_warm_stability = analyze_stability(results['no_warmup']['detailed_performance_metrics']['inference_times'])\n",
        "\n",
        "    stability_df = pd.DataFrame({\n",
        "        'Metric': ['Coefficient of Variation', 'Range (ms)', 'IQR (ms)'],\n",
        "        'With Warmup': [\n",
        "            warm_stability['coefficient_of_variation'],\n",
        "            warm_stability['range'],\n",
        "            warm_stability['iqr']\n",
        "        ],\n",
        "        'Without Warmup': [\n",
        "            no_warm_stability['coefficient_of_variation'],\n",
        "            no_warm_stability['range'],\n",
        "            no_warm_stability['iqr']\n",
        "        ]\n",
        "    })\n",
        "    print(stability_df.to_string(index=False))\n",
        "\n",
        "    # 4. Visualization\n",
        "    plot_dir = Path('analysis_plots')\n",
        "    plot_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Inference Time Distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.hist(results['warmup']['detailed_performance_metrics']['inference_times'],\n",
        "             bins=50, alpha=0.5, label='With Warmup')\n",
        "    plt.hist(results['no_warmup']['detailed_performance_metrics']['inference_times'],\n",
        "             bins=50, alpha=0.5, label='Without Warmup')\n",
        "    plt.title('Inference Time Distribution')\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.savefig(plot_dir / 'inference_time_distribution.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Time Series Plot\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(results['warmup']['detailed_performance_metrics']['inference_times'][:100],\n",
        "             label='With Warmup', alpha=0.7)\n",
        "    plt.plot(results['no_warmup']['detailed_performance_metrics']['inference_times'][:100],\n",
        "             label='Without Warmup', alpha=0.7)\n",
        "    plt.title('First 100 Inference Times')\n",
        "    plt.xlabel('Inference Number')\n",
        "    plt.ylabel('Time (ms)')\n",
        "    plt.legend()\n",
        "    plt.savefig(plot_dir / 'inference_time_series.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Component Breakdown\n",
        "    component_means = {\n",
        "        # 'Preprocessing': (np.mean(results['warmup']['detailed_performance_metrics']['preprocessing_times']),\n",
        "        #                 np.mean(results['no_warmup']['detailed_performance_metrics']['preprocessing_times'])),\n",
        "        'Invoke': (np.mean(results['warmup']['detailed_performance_metrics']['invoke_times']),\n",
        "                  np.mean(results['no_warmup']['detailed_performance_metrics']['invoke_times'])),\n",
        "        'Overhead': (np.mean(results['warmup']['detailed_performance_metrics']['overhead_times']),\n",
        "                    np.mean(results['no_warmup']['detailed_performance_metrics']['overhead_times']))\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = np.arange(len(component_means))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar(x - width/2, [v[0] for v in component_means.values()], width, label='With Warmup')\n",
        "    plt.bar(x + width/2, [v[1] for v in component_means.values()], width, label='Without Warmup')\n",
        "    plt.title('Average Time Components')\n",
        "    plt.xlabel('Component')\n",
        "    plt.ylabel('Time (ms)')\n",
        "    plt.xticks(x, component_means.keys())\n",
        "    plt.legend()\n",
        "    plt.savefig(plot_dir / 'time_components.png')\n",
        "    plt.close()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "9kiyF81c-ZLd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run analysis\n",
        "results = load_and_analyze_results('edge_tpu_inference.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EP9fE8J-xuG",
        "outputId": "3d341047-346f-4b0c-d5b3-aa6e03f39382"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Edge TPU Performance Analysis\n",
            "==================================================\n",
            "\n",
            "1. Basic Performance Metrics:\n",
            "------------------------------\n",
            "                     Metric  With Warmup  Without Warmup\n",
            "  First Inference Time (ms)     3.296054        3.296054\n",
            "Average Inference Time (ms)     3.660090        3.674524\n",
            "    Inference Time Std (ms)     0.317419        0.447161\n",
            "           Throughput (FPS)   273.217293      272.144074\n",
            "\n",
            "2. Detailed Timing Analysis:\n",
            "------------------------------\n",
            "             Metric  With Warmup  Without Warmup\n",
            "inference Mean (ms)     3.660090        3.674524\n",
            " inference Std (ms)     0.317419        0.447161\n",
            " inference P95 (ms)     4.202994        4.247833\n",
            " inference P99 (ms)     4.308867        4.317633\n",
            "   invoke Mean (ms)     3.046791        3.070708\n",
            "    invoke Std (ms)     0.293177        0.412730\n",
            "    invoke P95 (ms)     3.476361        3.661354\n",
            "    invoke P99 (ms)     3.686069        3.701945\n",
            " overhead Mean (ms)     0.613299        0.603816\n",
            "  overhead Std (ms)     0.098051        0.108635\n",
            "  overhead P95 (ms)     0.732968        0.726628\n",
            "  overhead P99 (ms)     1.043420        1.251845\n",
            "\n",
            "3. Performance Stability Analysis:\n",
            "------------------------------\n",
            "                  Metric  With Warmup  Without Warmup\n",
            "Coefficient of Variation     0.086724        0.121692\n",
            "              Range (ms)     1.620726        9.841363\n",
            "                IQR (ms)     0.521313        0.538563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EE5wQSNO-y9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}